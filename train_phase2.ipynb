{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code modified from: https://towardsdatascience.com/discover-the-sentiment-of-reddit-subgroup-using-roberta-model-10ab9a8271b8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Covid-CA/Election-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf phase2-models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "Some layers from the model checkpoint at vinai/bertweet-covid19-base-uncased were not used when initializing TFRobertaForSequenceClassification: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-covid19-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "38/38 [==============================] - 38s 1000ms/step - loss: 1.0791 - accuracy: 0.5789 - val_loss: 0.8745 - val_accuracy: 0.6600\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 35s 914ms/step - loss: 0.7121 - accuracy: 0.7366 - val_loss: 0.7917 - val_accuracy: 0.6900\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 35s 918ms/step - loss: 0.3555 - accuracy: 0.8877 - val_loss: 0.8645 - val_accuracy: 0.7267\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 35s 916ms/step - loss: 0.1692 - accuracy: 0.9541 - val_loss: 1.2648 - val_accuracy: 0.6800\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 35s 915ms/step - loss: 0.1100 - accuracy: 0.9674 - val_loss: 1.2938 - val_accuracy: 0.6767\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 35s 915ms/step - loss: 0.1171 - accuracy: 0.9645 - val_loss: 1.2130 - val_accuracy: 0.6967\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 35s 914ms/step - loss: 0.0413 - accuracy: 0.9900 - val_loss: 1.4241 - val_accuracy: 0.7167\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 35s 913ms/step - loss: 0.0406 - accuracy: 0.9900 - val_loss: 1.3880 - val_accuracy: 0.7300\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 35s 914ms/step - loss: 0.0190 - accuracy: 0.9958 - val_loss: 1.5524 - val_accuracy: 0.7100\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 35s 913ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 1.5185 - val_accuracy: 0.7333\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 35s 916ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 1.5806 - val_accuracy: 0.7400\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 35s 914ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 1.5737 - val_accuracy: 0.7400\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 35s 914ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 1.7578 - val_accuracy: 0.7067\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 35s 915ms/step - loss: 0.0446 - accuracy: 0.9871 - val_loss: 1.6144 - val_accuracy: 0.6700\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 35s 913ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 1.8094 - val_accuracy: 0.6700\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 35s 919ms/step - loss: 0.0603 - accuracy: 0.9821 - val_loss: 1.6320 - val_accuracy: 0.7200\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 35s 913ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 1.6652 - val_accuracy: 0.7367\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 35s 914ms/step - loss: 0.0919 - accuracy: 0.9745 - val_loss: 1.5514 - val_accuracy: 0.7100\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 35s 915ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 1.6538 - val_accuracy: 0.7300\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 35s 919ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 1.7549 - val_accuracy: 0.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f44f2d317d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_datasets as tfds\n",
    "from transformers import TFRobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaConfig, AutoTokenizer\n",
    "import os\n",
    "\n",
    "\n",
    "# Load your Dataset\n",
    "train_tweets = pd.read_csv('data/Covid_CA_new.csv').dropna()\n",
    "# train_tweets = pd.read_csv('data/Election16_new.csv').dropna()\n",
    "training_sentences, testing_sentences = train_test_split(train_tweets[['text', 'target']],\n",
    "                                                         test_size=0.2)\n",
    "# model initialization\n",
    "model = TFRobertaForSequenceClassification.from_pretrained(\"vinai/bertweet-covid19-base-uncased\", num_labels=5)\n",
    "# model = TFRobertaForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=5)\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-covid19-base-uncased\", use_fast=False)\n",
    "# roberta_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
    "\n",
    "max_length = 128\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "def convert_example_to_feature(review):\n",
    "    # combine step for tokenization, WordPiece vector mapping and will\n",
    "    # add also special tokens and truncate reviews longer than our max length\n",
    "    return roberta_tokenizer.encode_plus(review,\n",
    "                                 add_special_tokens=True,  # add [CLS], [SEP]\n",
    "                                 max_length=max_length,  # max length of the text that can go to RoBERTa\n",
    "                                 pad_to_max_length=True,  # add [PAD] tokens at the end of sentence\n",
    "                                 return_attention_mask=True,  # add attention mask to not focus on pad tokens\n",
    "                                 )\n",
    "\n",
    "# map to the expected input to TFRobertaForSequenceClassification, see here\n",
    "def map_example_to_dict(input_ids, attention_masks, label):\n",
    "    return {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "           }, label\n",
    "\n",
    "def encode_examples(ds, limit=-1):\n",
    "    # Prepare Input list\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    label_list = []\n",
    "\n",
    "    if (limit > 0):\n",
    "        ds = ds.take(limit)\n",
    "\n",
    "    for review, label in tfds.as_numpy(ds):\n",
    "        bert_input = convert_example_to_feature(review.decode())\n",
    "        input_ids_list.append(bert_input['input_ids'])\n",
    "        attention_mask_list.append(bert_input['attention_mask'])\n",
    "        label_list.append([label])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((input_ids_list,\n",
    "                                               attention_mask_list,\n",
    "                                               label_list)).map(map_example_to_dict)\n",
    "\n",
    "training_sentences_modified = tf.data.Dataset.from_tensor_slices((training_sentences['text'],\n",
    "                                                                  training_sentences['target']))\n",
    "\n",
    "testing_sentences_modified = tf.data.Dataset.from_tensor_slices((testing_sentences['text'],\n",
    "                                                                 testing_sentences['target']))\n",
    "\n",
    "ds_train_encoded = encode_examples(training_sentences_modified).repeat(2).shuffle(10000).batch(batch_size)\n",
    "ds_test_encoded = encode_examples(testing_sentences_modified).batch(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 7e-5\n",
    "number_of_epochs = 20\n",
    "\n",
    "class ModelMetrics(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.count_n = 1\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        \n",
    "        os.mkdir('phase2-models' + str(self.count_n))\n",
    "        self.model.save_pretrained('phase2-models' + str(self.count_n)) # this folder address should match with folder we created above\n",
    "\n",
    "        self.count_n += 1\n",
    "\n",
    "metrics = ModelMetrics()\n",
    "\n",
    "# model.layers[0].trainable = False\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "model.fit(ds_train_encoded, epochs=number_of_epochs,\n",
    "          validation_data=ds_test_encoded, callbacks=[metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on 2020 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "\n",
    "def predict(test_tweets, model, output_name):\n",
    "    for i,v in enumerate(test_tweets['text']):\n",
    "        test_tweets.loc[i,'processed_text'] = p.clean(v)\n",
    "\n",
    "    test_tweets['target'] = 0\n",
    "    # prepare data as per RoBERTa model input\n",
    "    submission_sentences_modified = tf.data.Dataset.from_tensor_slices((test_tweets['processed_text'],\n",
    "                                                              test_tweets['target']))\n",
    "    ds_submission_encoded = encode_examples(submission_sentences_modified).batch(batch_size)\n",
    "\n",
    "    # predict sentiment of Reddit comments\n",
    "    submission_pre = tf.nn.softmax(model.predict(ds_submission_encoded))\n",
    "    submission_pre_argmax = tf.math.argmax(submission_pre[0], axis=1)\n",
    "    test_tweets['target'] = submission_pre_argmax\n",
    "    test_tweets.to_csv(output_name, index=False) # save to file\n",
    "    return test_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('data/Election20.csv')\n",
    "data2 = pd.read_csv('data/Covid_US.csv')\n",
    "data1['label'] = 'election'\n",
    "data2['label'] = 'covid'\n",
    "test_data = pd.concat([data1, data2])\n",
    "test_data = test_data.sample(frac=1) # shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2317</td>\n",
       "      <td>2317</td>\n",
       "      <td>2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2268</td>\n",
       "      <td>2164</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Thu Aug 20 18:35:07 +0000 2020</td>\n",
       "      <td>RT @realDonaldTrump: Many more people would ha...</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  time  \\\n",
       "count                             2317   \n",
       "unique                            2268   \n",
       "top     Thu Aug 20 18:35:07 +0000 2020   \n",
       "freq                                 3   \n",
       "\n",
       "                                                     text     label  \n",
       "count                                                2317      2317  \n",
       "unique                                               2164         2  \n",
       "top     RT @realDonaldTrump: Many more people would ha...  election  \n",
       "freq                                                    8      1298  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data.reset_index(drop=True)\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thu Oct 22 18:23:59 +0000 2020</td>\n",
       "      <td>RT @BillOReilly: Lesley Stahl denies the econo...</td>\n",
       "      <td>covid</td>\n",
       "      <td>: Lesley Stahl denies the economy before the p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Oct 07 18:17:08 +0000 2020</td>\n",
       "      <td>RT @CaslerNoel: The first time I heard a story...</td>\n",
       "      <td>election</td>\n",
       "      <td>: The first time I heard a story about Trump r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Oct 21 18:20:29 +0000 2020</td>\n",
       "      <td>RT @seanhannity: BREAKING: Jim Jordan Says Sta...</td>\n",
       "      <td>election</td>\n",
       "      <td>: BREAKING: Jim Jordan Says Staff Has Independ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue Oct 06 18:22:43 +0000 2020</td>\n",
       "      <td>RT @AntillanaSoy_: nobody recovers from COVID-...</td>\n",
       "      <td>covid</td>\n",
       "      <td>: nobody recovers from COVID-19 in days ... sp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue Aug 18 18:01:22 +0000 2020</td>\n",
       "      <td>RT @phatpussymo: Like cool... but she’s dead a...</td>\n",
       "      <td>election</td>\n",
       "      <td>: Like cool... but shes dead and theres thousa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>Tue Oct 06 18:29:05 +0000 2020</td>\n",
       "      <td>RT @Christo29932651: @kimKBaltimore 60 years o...</td>\n",
       "      <td>election</td>\n",
       "      <td>: years of incremental feminization &amp;amp; atta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>Tue Sep 29 18:09:36 +0000 2020</td>\n",
       "      <td>RT @kylegriffin1: Inbox: Biden for President a...</td>\n",
       "      <td>covid</td>\n",
       "      <td>: Inbox: Biden for President announced Joe Bid...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>Wed Oct 07 18:48:34 +0000 2020</td>\n",
       "      <td>RT @NikkoGuy: my mental health during coronavi...</td>\n",
       "      <td>covid</td>\n",
       "      <td>: my mental health during coronavirus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>Wed Sep 30 18:32:19 +0000 2020</td>\n",
       "      <td>@BillCorbett Was freshman in highschool at age...</td>\n",
       "      <td>election</td>\n",
       "      <td>Was freshman in highschool at age , quite diff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>Mon Sep 28 18:28:52 +0000 2020</td>\n",
       "      <td>RT @MK_____813: A billionaire paid $750 in tax...</td>\n",
       "      <td>covid</td>\n",
       "      <td>: A billionaire paid $750 in taxes but Im supp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2317 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                time  \\\n",
       "0     Thu Oct 22 18:23:59 +0000 2020   \n",
       "1     Wed Oct 07 18:17:08 +0000 2020   \n",
       "2     Wed Oct 21 18:20:29 +0000 2020   \n",
       "3     Tue Oct 06 18:22:43 +0000 2020   \n",
       "4     Tue Aug 18 18:01:22 +0000 2020   \n",
       "...                              ...   \n",
       "2312  Tue Oct 06 18:29:05 +0000 2020   \n",
       "2313  Tue Sep 29 18:09:36 +0000 2020   \n",
       "2314  Wed Oct 07 18:48:34 +0000 2020   \n",
       "2315  Wed Sep 30 18:32:19 +0000 2020   \n",
       "2316  Mon Sep 28 18:28:52 +0000 2020   \n",
       "\n",
       "                                                   text     label  \\\n",
       "0     RT @BillOReilly: Lesley Stahl denies the econo...     covid   \n",
       "1     RT @CaslerNoel: The first time I heard a story...  election   \n",
       "2     RT @seanhannity: BREAKING: Jim Jordan Says Sta...  election   \n",
       "3     RT @AntillanaSoy_: nobody recovers from COVID-...     covid   \n",
       "4     RT @phatpussymo: Like cool... but she’s dead a...  election   \n",
       "...                                                 ...       ...   \n",
       "2312  RT @Christo29932651: @kimKBaltimore 60 years o...  election   \n",
       "2313  RT @kylegriffin1: Inbox: Biden for President a...     covid   \n",
       "2314  RT @NikkoGuy: my mental health during coronavi...     covid   \n",
       "2315  @BillCorbett Was freshman in highschool at age...  election   \n",
       "2316  RT @MK_____813: A billionaire paid $750 in tax...     covid   \n",
       "\n",
       "                                         processed_text  target  \n",
       "0     : Lesley Stahl denies the economy before the p...       1  \n",
       "1     : The first time I heard a story about Trump r...       1  \n",
       "2     : BREAKING: Jim Jordan Says Staff Has Independ...       1  \n",
       "3     : nobody recovers from COVID-19 in days ... sp...       1  \n",
       "4     : Like cool... but shes dead and theres thousa...       1  \n",
       "...                                                 ...     ...  \n",
       "2312  : years of incremental feminization &amp; atta...       1  \n",
       "2313  : Inbox: Biden for President announced Joe Bid...       2  \n",
       "2314              : my mental health during coronavirus       2  \n",
       "2315  Was freshman in highschool at age , quite diff...       1  \n",
       "2316  : A billionaire paid $750 in taxes but Im supp...       1  \n",
       "\n",
       "[2317 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test_data, model, 'predict-data/Covid_model_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
